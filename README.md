# Cedit-Risk_XAI

The large retail/corporate banking systems intend to use AI/ML based automated solutions for credit risk modelling using various techniques in ML such as Classification, Regression, Deep Neural Network etc. Neural networks, random forests and gradient boosting machines are all “universal approximators” that can model continuous functions. However, two major problems arise when AI is used for Credit Risk modelling. i. As there is no explanation as why a customer would be considered defaulter, experts are hesitant to put their trust on the output as it may be biased or incorrect. ii. Regulatory obligations in Credit risk modelling, particularly in the EU (GDPR) & United States (FCRA), require that models be explainable and actionable. For example, using an incorrectly designed ML-based credit score, there will be consumers who decrease their total balance on revolving cards but observe ML-based credit score decrease. This results in a harmful action to the consumer who acted logically and thus may result in violation of the above mentioned regulation. To solve this problem we shall use XAI at XAI interface points of a ML/Data Science project and show how using explainability, the trust and reliability of the AI projects can be enhanced. In this project we aim to : i. To use Interpretability as a means of explanations for different models used in Credit Risk Modelling and provide an explanations interface to the users. ii. To evaluate Interpretability of different models and also to derive key factors in credit risk classification using the evaluated models.

